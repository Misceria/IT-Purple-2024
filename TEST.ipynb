{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9139cbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import sklearn\n",
    "import time\n",
    "\n",
    "data = pd.read_parquet('train_data.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debea463",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Полезные частые функции\n",
    "\n",
    "useless_columns = ['id', 'target', 'sample_ml_new', 'feature68', 'feature69', 'feature144', 'feature160',\n",
    "                   'feature292', 'feature406', 'feature407', 'feature496', 'feature511',\n",
    "                   'feature625', 'feature661', 'feature663', 'feature669', 'feature678',\n",
    "                   'feature683', 'feature686', 'feature710', 'feature756', 'feature761',\n",
    "                   'feature765', 'feature801', 'feature802', 'feature806', 'feature807',\n",
    "                   'feature808', 'feature809', 'feature816', 'feature818', 'feature819',\n",
    "                   'feature955', 'feature956', 'feature957', 'feature958', 'feature959',\n",
    "                   'feature960', 'feature961', 'feature962', 'feature963', 'feature964',\n",
    "                   'feature965', 'feature966', 'feature967', 'feature968', 'feature969',\n",
    "                   'feature970', 'feature971', 'feature972', 'feature973', 'feature974', \n",
    "                   'feature975', 'feature976', 'feature977', 'feature978', 'feature979',\n",
    "                   'feature980', 'feature981', 'feature982', 'feature983', 'feature984', \n",
    "                   'feature1005', 'feature1006', 'feature1007', 'feature1008', 'feature1009',\n",
    "                   'feature1010', 'feature1011', 'feature1012', 'feature1013', 'feature1014',\n",
    "                   'feature1015', 'feature1016', 'feature1017', 'feature1018', 'feature1019',\n",
    "                   'feature1020', 'feature1021', 'feature1022', 'feature1023', 'feature1024',\n",
    "                   'feature1025', 'feature1026', 'feature1027', 'feature1028', 'feature1029',\n",
    "                   'feature1030', 'feature1031', 'feature1032', 'feature1033', 'feature1034']\n",
    "\n",
    "\n",
    "def metrics(y_true, y_preds):\n",
    "    acc = sklearn.metrics.accuracy_score(y_true, y_preds)  \n",
    "    rec = sklearn.metrics.recall_score(y_true, y_preds, average=None)\n",
    "    f1 = sklearn.metrics.f1_score(y_true, y_preds)\n",
    "    prec = \tsklearn.metrics.precision_score(y_true, y_preds)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_true, y_preds)\n",
    "    print('test-accuracy:', acc, ' \\ntest-recall:', rec, '\\ntest-f1_score:', f1, '\\ntest-precision_score:', prec, '\\ntest-roc_auc_score:', auc)\n",
    "    \n",
    "\n",
    "\n",
    "def equallySample(data):\n",
    "    y_data = data[\"target\"]\n",
    "    x_data = data.drop(useless_columns, axis=1)\n",
    "    sample_size = 17000 # Задайте желаемое количество строк для каждого класса\n",
    "    frames = []\n",
    "    classes = data['target'].unique()\n",
    "\n",
    "    for i in classes:\n",
    "        if i == 0:  \n",
    "            g = data[data['target'] == i].sample(sample_size)\n",
    "        else:\n",
    "            g = data[data['target'] == i].sample(sample_size)\n",
    "        frames.append(g)\n",
    "\n",
    "    equally_sampled = pd.concat(frames)\n",
    "    equally_sampled['target'].value_counts()\n",
    "\n",
    "    X_train_equally_sampled, X_test_equally_sampled, y_train_equally_sampled,  y_test_equally_sampled = sklearn.model_selection.train_test_split(x_data, y_data, test_size=0.25, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc61709",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics([0, 1, 1, 0, 1, 1, 1], [1, 0, 1, 0, 0, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c582df4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "useless_columns = ['id', 'target', 'sample_ml_new', 'feature68', 'feature69', 'feature144', 'feature160',\n",
    "                   'feature292', 'feature406', 'feature407', 'feature496', 'feature511',\n",
    "                   'feature625', 'feature661', 'feature663', 'feature669', 'feature678',\n",
    "                   'feature683', 'feature686', 'feature710', 'feature756', 'feature761',\n",
    "                   'feature765', 'feature801', 'feature802', 'feature806', 'feature807',\n",
    "                   'feature808', 'feature809', 'feature816', 'feature818', 'feature819',\n",
    "                   'feature955', 'feature956', 'feature957', 'feature958', 'feature959',\n",
    "                   'feature960', 'feature961', 'feature962', 'feature963', 'feature964',\n",
    "                   'feature965', 'feature966', 'feature967', 'feature968', 'feature969',\n",
    "                   'feature970', 'feature971', 'feature972', 'feature973', 'feature974', \n",
    "                   'feature975', 'feature976', 'feature977', 'feature978', 'feature979',\n",
    "                   'feature980', 'feature981', 'feature982', 'feature983', 'feature984', \n",
    "                   'feature1005', 'feature1006', 'feature1007', 'feature1008', 'feature1009',\n",
    "                   'feature1010', 'feature1011', 'feature1012', 'feature1013', 'feature1014',\n",
    "                   'feature1015', 'feature1016', 'feature1017', 'feature1018', 'feature1019',\n",
    "                   'feature1020', 'feature1021', 'feature1022', 'feature1023', 'feature1024',\n",
    "                   'feature1025', 'feature1026', 'feature1027', 'feature1028', 'feature1029',\n",
    "                   'feature1030', 'feature1031', 'feature1032', 'feature1033', 'feature1034']\n",
    "\n",
    "\n",
    "y_data = data[\"target\"]\n",
    "x_data = data.drop(useless_columns, axis=1)\n",
    "x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7813b92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train,  y_test = sklearn.model_selection.train_test_split(x_data, y_data, test_size=0.25, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a0c8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EQual size of targets\n",
    "\n",
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())\n",
    "\n",
    "\n",
    "sample_size = 17000 # Задайте желаемое количество строк для каждого класса\n",
    "frames = []\n",
    "classes = data['target'].unique()\n",
    "\n",
    "for i in classes:\n",
    "    if i == 0:  \n",
    "        g = data[data['target'] == i].sample(sample_size)\n",
    "    else:\n",
    "        g = data[data['target'] == i].sample(sample_size)\n",
    "    frames.append(g)\n",
    "\n",
    "equally_sampled = pd.concat(frames)\n",
    "equally_sampled['target'].value_counts()\n",
    "\n",
    "X_train_equally_sampled, X_test_equally_sampled, y_train_equally_sampled,  y_test_equally_sampled = sklearn.model_selection.train_test_split(x_data, y_data, test_size=0.25, shuffle=True)\n",
    "\"\"\"X_train_xgb_equally_sampled = xgb.DMatrix(X_train_equally_sampled, label=y_train_equally_sampled)\n",
    "X_test_xgb_equally_sampled = xgb.DMatrix(X_test_equally_sampled, label=y_test_equally_sampled)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bba7465",
   "metadata": {},
   "outputs": [],
   "source": [
    "equally_sampled['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d9eda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_data = xgb.DMatrix(x_data, label=y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87997bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'max_depth': 4,\n",
    "          'eta': 1,\n",
    "          'objective': \"binary:logistic\",\n",
    "          'nthread': -1,\n",
    "          'eval_metric': ['auc', 'map']}\n",
    "eval_list = [(X_test_xgb, \"Everything\")]\n",
    "num_rounds = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ac0cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "evals_result = dict()\n",
    "\n",
    "def objective(n_estimators, max_depth, classes_weight_o, learning_rate, gamma):\n",
    "    n_estimators = int(n_estimators)\n",
    "    max_depth = int(max_depth)\n",
    "    classes_weight_o = int(classes_weight_o)\n",
    "    classes_weights = class_weight.compute_sample_weight(\n",
    "    class_weight={0:1, 1:classes_weight_o},\n",
    "    y=y_train\n",
    ")   \n",
    "\n",
    "    \n",
    "    xgb_model = xgb.XGBClassifier(  n_estimators=n_estimators,\n",
    "                                    max_depth=max_depth,\n",
    "                                    learning_rate=learning_rate,\n",
    "                                    booster=\"gbtree\",\n",
    "                                    n_jobs=-1,\n",
    "                                    eval_metric=['auc', 'pre'],\n",
    "                                    gamma=gamma)\n",
    "\n",
    "    xgb_model.fit(X_train, y_train, eval_set=eval_list, sample_weight=classes_weights)\n",
    "    preds = xgb_model.predict(X_test)\n",
    "    return sklearn.metrics.f1_score(y_test, preds)\n",
    "\n",
    "\"\"\"parameters = {\n",
    "    'max_depth': [4, 20],\n",
    "    'learning_rate': [0.2],\n",
    "    'n_estimators': [20, 40],\n",
    "}\n",
    "\n",
    "params = {'max_depth': 6,\n",
    "          'eta': 1,\n",
    "          'objective': \"binary:logistic\",\n",
    "          'nthread': -1,\n",
    "          'eval_metric': ['auc', 'pre'],\n",
    "          'class_weight': {0:0.1, 1:100}}\"\"\"\n",
    "eval_list = [(X_test, y_test)]\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "\"\"\"classes_weights = class_weight.compute_sample_weight(\n",
    "    class_weight={0:1, 1:22},\n",
    "    y=y_train\n",
    ")\"\"\"\n",
    "#clf = sklearn.model_selection.GridSearchCV(xgb_model, parameters, scoring='f1_micro', n_jobs=-1, verbose=10)\n",
    "\n",
    "search_space = {\n",
    "    'max_depth': (4, 20),\n",
    "    'n_estimators': (10, 70),\n",
    "    \"classes_weight_o\": (10, 40),\n",
    "    'learning_rate': (0.001, 0.2),\n",
    "    'gamma': (0.01, 5)\n",
    "}\n",
    "import bayes_opt\n",
    "optimizer = bayes_opt.BayesianOptimization(\n",
    "                                f=objective,\n",
    "                                pbounds=search_space,\n",
    "                                random_state=12,\n",
    "                                allow_duplicate_points=True\n",
    "                              ) \n",
    "\n",
    "opt = optimizer.maximize(init_points=2, n_iter=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902c4cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.max['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbeaddcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_weights = class_weight.compute_sample_weight(\n",
    "    class_weight={0:1, 1:31},\n",
    "    y=y_train\n",
    ")   \n",
    "\n",
    "xgb_model = xgb.XGBClassifier(  gamma=4.8,\n",
    "                                learning_rate=0.152,\n",
    "                                max_depth=8,\n",
    "                                n_estimators=18,\n",
    "                                booster=\"gbtree\",\n",
    "                                n_jobs=-1,\n",
    "                                eval_metric=['auc', 'pre'],\n",
    "                                early_stopping_rounds=10)\n",
    "\n",
    "xgb_model.fit(X_train, y_train, eval_set=eval_list, sample_weight=classes_weights)\n",
    "preds = xgb_model.predict(X_test)\n",
    "metrics(y_test, preds)\n",
    "\n",
    "\n",
    "\"\"\"{'classes_weight_o': 31.438781865708886,\n",
    " 'gamma': 4.806812881469824,\n",
    " 'learning_rate': 0.15290427033360873,\n",
    " 'max_depth': 8.582152510429442,\n",
    " 'n_estimators': 18.513852056962605}\n",
    "                                    test-accuracy: 0.7220024017736174  \n",
    "                                    test-recall: [0.72583707 0.61577552] \n",
    "                                    test-f1_score: 0.13371074915441264 \n",
    "                                    test-precision_score: 0.07499798175506579 \n",
    "                                    test-roc_auc_score: 0.6708062939632549\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24eb72f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_preds = xgb_model.predict(X_test)\n",
    "y_true = list(y_test)\n",
    "print(*y_preds)\n",
    "\n",
    "#ev = clf.eval(X_test)\n",
    "metrics(y_true, y_preds)\n",
    "#print(ev, ' eval-recall:')\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_preds, y_test))\n",
    "cm = confusion_matrix(y_preds, y_test)\n",
    "acc = cm.diagonal().sum()/cm.sum()\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4529c1",
   "metadata": {},
   "source": [
    "# GRIDSEARCH XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508557a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'max_depth': range(2,10,2),\n",
    "    'learning_rate': np.linspace(.1, .6, 6),\n",
    "    'min_child_weight': range(1,10,2),\n",
    "}\n",
    "\n",
    "grid = sklearn.model_selection.GridSearchCV(\n",
    "    estimator = xgb.XGBClassifier(n_jobs=-1,\n",
    "                              n_estimators=500,\n",
    "                              random_state=0),\n",
    "    param_grid = params,\n",
    "    scoring='f1',  # <------Use `scoring` instead of `eval_metric`\n",
    ")\n",
    "\n",
    "eval_set = [(X_train_equally_sampled, y_train_equally_sampled),\n",
    "            (X_test_equally_sampled, y_test_equally_sampled)]\n",
    "\n",
    "grid.fit(X_train_equally_sampled, y_train_equally_sampled,\n",
    "         eval_set=eval_set,\n",
    "         early_stopping_rounds=25,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ca7743",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4af0bf2",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['feature5'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea000a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['feature2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3266a773",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=140\n",
    "corr = data[['target', 'feature'+str(x), 'feature'+str(x+1), 'feature'+str(x+2), 'feature'+str(x+3), \n",
    "                'feature'+str(x+4), 'feature'+str(x+5), 'feature'+str(x+6), 'feature'+str(x+7), 'feature'+str(x+8),\n",
    "                'feature'+str(x+9)]].corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6ff513",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot = data.boxplot(\"feature5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a7fef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import xgboost as xgb\n",
    "\n",
    "useless_columns = ['id', 'target', 'sample_ml_new', 'feature68', 'feature69', 'feature144', 'feature160',\n",
    "                   'feature292', 'feature406', 'feature407', 'feature496', 'feature511',\n",
    "                   'feature625', 'feature661', 'feature663', 'feature669', 'feature678',\n",
    "                   'feature683', 'feature686', 'feature710', 'feature756', 'feature761',\n",
    "                   'feature765', 'feature801', 'feature802', 'feature806', 'feature807',\n",
    "                   'feature808', 'feature809', 'feature816', 'feature818', 'feature819',\n",
    "                   'feature955', 'feature956', 'feature957', 'feature958', 'feature959',\n",
    "                   'feature960', 'feature961', 'feature962', 'feature963', 'feature964',\n",
    "                   'feature965', 'feature966', 'feature967', 'feature968', 'feature969',\n",
    "                   'feature970', 'feature971', 'feature972', 'feature973', 'feature974', \n",
    "                   'feature975', 'feature976', 'feature977', 'feature978', 'feature979',\n",
    "                   'feature980', 'feature981', 'feature982', 'feature983', 'feature984', \n",
    "                   'feature1005', 'feature1006', 'feature1007', 'feature1008', 'feature1009',\n",
    "                   'feature1010', 'feature1011', 'feature1012', 'feature1013', 'feature1014',\n",
    "                   'feature1015', 'feature1016', 'feature1017', 'feature1018', 'feature1019',\n",
    "                   'feature1020', 'feature1021', 'feature1022', 'feature1023', 'feature1024',\n",
    "                   'feature1025', 'feature1026', 'feature1027', 'feature1028', 'feature1029',\n",
    "                   'feature1030', 'feature1031', 'feature1032', 'feature1033', 'feature1034']\n",
    "\n",
    "data = pd.read_parquet('train_data.parquet', engine='pyarrow')\n",
    "y_data = data[\"target\"]\n",
    "\n",
    "x_data = data.drop(useless_columns, axis=1)\n",
    "print(x_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e45782",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train,  y_test = sklearn.model_selection.train_test_split(x_data, y_data, test_size=0.25, shuffle=True)\n",
    "\n",
    "X_train_xgb = xgb.DMatrix(X_train, label=y_train)\n",
    "X_test_xgb = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf370b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# impute\n",
    "train_data_num = X_train.select_dtypes(exclude=['object'])\n",
    "test_data_num = X_test.select_dtypes(exclude=['object'])\n",
    "imputer = SimpleImputer()\n",
    "train_num_cleaned = imputer.fit_transform(train_data_num)\n",
    "test_num_cleaned = imputer.transform(test_data_num)\n",
    "\n",
    "# columns rename after imputing\n",
    "train_num_cleaned = pd.DataFrame(train_num_cleaned)\n",
    "test_num_cleaned = pd.DataFrame(test_num_cleaned)\n",
    "train_num_cleaned.columns = train_data_num.columns\n",
    "test_num_cleaned.columns = test_data_num.columns\n",
    "\n",
    "\n",
    "cols_with_missing = [col for col in train_num_cleaned.columns\n",
    "                                if test_num_cleaned[col].isnull().any()]\n",
    "print(cols_with_missing)\n",
    "for col in cols_with_missing:\n",
    "    print(col, test_num_cleaned[col].isnull().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79906be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Изменение веса классов\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_data), y=y_data)\n",
    "\n",
    "# Создание модели с взвешиванием классов\n",
    "model = RandomForestClassifier(n_estimators=30, class_weight={0: 0.5, 1: 500.0})\n",
    "model.fit(train_num_cleaned, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bb4fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(test_num_cleaned)\n",
    "preds = list(map(round, preds))\n",
    "y_true = list(y_test)\n",
    "print(preds.count(1))\n",
    "#ev = bst.eval(X_test_xgb)\n",
    "\n",
    "\n",
    "rec = sklearn.metrics.recall_score(y_true, preds)\n",
    "f1 = sklearn.metrics.f1_score(y_true, preds)\n",
    "prec = \tsklearn.metrics.precision_score(y_true, preds)\n",
    "auc = sklearn.metrics.roc_auc_score(y_true, preds)\n",
    "print(' test-recall:', rec, ' test-f1_score:', f1, ' test-precision_score:', prec, ' test-roc_auc_score:', auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cce962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Методы борьбы с дисбалансом данных\n",
    "import sklearn\n",
    "print(sklearn.__version__)\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "data = pd.read_parquet('train_data.parquet', engine='pyarrow')\n",
    "y_data = data[\"target\"]\n",
    "x_data = data.drop(useless_columns, axis=1)\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "X_train, X_test, y_train,  y_test = sklearn.model_selection.train_test_split(x_data, y_data, test_size=0.25, shuffle=True)\n",
    "\n",
    "# impute\n",
    "train_data_num = X_train.select_dtypes(exclude=['object'])\n",
    "test_data_num = X_test.select_dtypes(exclude=['object'])\n",
    "imputer = SimpleImputer()\n",
    "train_num_cleaned = imputer.fit_transform(train_data_num)\n",
    "test_num_cleaned = imputer.transform(test_data_num)\n",
    "\n",
    "# columns rename after imputing\n",
    "train_num_cleaned = pd.DataFrame(train_num_cleaned)\n",
    "test_num_cleaned = pd.DataFrame(test_num_cleaned)\n",
    "train_num_cleaned.columns = train_data_num.columns\n",
    "test_num_cleaned.columns = test_data_num.columns\n",
    "\n",
    "# Создание экземпляра SMOTE\n",
    "smote = SMOTE()\n",
    "\n",
    "# Применение SMOTE к данным\n",
    "X_resampled, y_resampled = smote.fit_resample(train_num_cleaned, y_train)\n",
    "\n",
    "X_resampled_xgb = xgb.DMatrix(X_resampled, y_resampled)\n",
    "X_test_xgb = xgb.DMatrix(test_num_cleaned, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7482cb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'max_depth': 8,\n",
    "          'eta': 1,\n",
    "          'objective': \"binary:logistic\",\n",
    "          'nthread': -1,\n",
    "          'eval_metric': ['auc', 'pre']}\n",
    "eval_list = [(X_test_xgb, \"Everything\")]\n",
    "num_rounds = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f23f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef3f4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "evals_result = dict()\n",
    "bst = xgb.train(params, X_resampled_xgb, num_rounds, eval_list, evals=X_test_xgb, evals_result=evals_result)\n",
    "y_preds = bst.predict(X_test_xgb)\n",
    "preds = list(map(round, preds))\n",
    "y_true = list(y_test)\n",
    "metrics(y_true, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad67914",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics(y_true, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2e80bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение каждой моделей члена на подмножестве данных\n",
    "\n",
    "data = pd.read_parquet('train_data.parquet', engine='pyarrow')\n",
    "y_data = data[\"target\"]\n",
    "x_data = data.drop(useless_columns, axis=1)\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "X_train, X_test, y_train,  y_test = sklearn.model_selection.train_test_split(x_data, y_data, test_size=0.25, shuffle=True)\n",
    "\n",
    "# impute\n",
    "train_data_num = X_train.select_dtypes(exclude=['object'])\n",
    "test_data_num = X_test.select_dtypes(exclude=['object'])\n",
    "imputer = SimpleImputer()\n",
    "train_num_cleaned = imputer.fit_transform(train_data_num)\n",
    "test_num_cleaned = imputer.transform(test_data_num)\n",
    "\n",
    "# columns rename after imputing\n",
    "train_num_cleaned = pd.DataFrame(train_num_cleaned)\n",
    "test_num_cleaned = pd.DataFrame(test_num_cleaned)\n",
    "train_num_cleaned.columns = train_data_num.columns\n",
    "test_num_cleaned.columns = test_data_num.columns\n",
    "\n",
    "X_train_xgb = xgb.DMatrix(train_num_cleaned, y_train)\n",
    "X_test_xgb = xgb.DMatrix(test_num_cleaned, y_train)\n",
    "\n",
    "eval_list = [(X_test_xgb, \"Everything\")]\n",
    "num_rounds = 40\n",
    "ensemble = [xgb.train({'max_depth': x,\n",
    "          'eta': 1,\n",
    "          'objective': \"binary:logistic\",\n",
    "          'nthread': -1,\n",
    "          'eval_metric': ['auc', 'pre']}, X_train_xgb, num_rounds, eval_list, evals=X_test_xgb, evals_result=evals_result) for x in range(2, 10)]\n",
    "ind = 1\n",
    "\n",
    "\"\"\"for model in ensemble:\n",
    "    sample_indices = np.random.choice(len(X_train), size=len(X_train), replace=True)\n",
    "    X_subset, y_subset = X_train[sample_indices], y_train[sample_indices]\n",
    "    model.fit(X_subset, y_subset)\n",
    "    print(f\"Модель {ind} обучена\")\n",
    "    ind +=1\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e4da61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mode\n",
    "predictions = np.array([model.predict(X_test_xgb) for model in ensemble])\n",
    "new_predictions=[]\n",
    "for x in range(len(predictions[0])):\n",
    "    new_predictions.append(np.array([predictions[y][x] for y in range(len(predictions))]))\n",
    "ensemble_predictions = [int(mode(x.round())) for x in new_predictions]\n",
    "# Используем np.argmax для нахождения индекса наиболее часто встречающегося значения\n",
    "\n",
    "metrics(y_test, ensemble_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb26519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Кросс-обучение\n",
    "\n",
    "data = pd.read_parquet('train_data.parquet', engine='pyarrow')\n",
    "y_data = data[\"target\"]\n",
    "x_data = data.drop(useless_columns, axis=1)\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "X_train, X_test, y_train,  y_test = sklearn.model_selection.train_test_split(x_data, y_data, test_size=0.25, shuffle=True)\n",
    "\n",
    "# impute\n",
    "train_data_num = X_train.select_dtypes(exclude=['object'])\n",
    "test_data_num = X_test.select_dtypes(exclude=['object'])\n",
    "imputer = SimpleImputer()\n",
    "train_num_cleaned = imputer.fit_transform(train_data_num)\n",
    "test_num_cleaned = imputer.transform(test_data_num)\n",
    "\n",
    "# columns rename after imputing\n",
    "train_num_cleaned = pd.DataFrame(train_num_cleaned)\n",
    "test_num_cleaned = pd.DataFrame(test_num_cleaned)\n",
    "train_num_cleaned.columns = train_data_num.columns\n",
    "test_num_cleaned.columns = test_data_num.columns\n",
    "\n",
    "X_train_xgb = xgb.DMatrix(train_num_cleaned, y_train)\n",
    "X_test_xgb = xgb.DMatrix(test_num_cleaned, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b8382d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet('train_data.parquet', engine='pyarrow')\n",
    "y_data = data[\"target\"]\n",
    "x_data = data.drop(useless_columns, axis=1)\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "X_train, X_test, y_train,  y_test = sklearn.model_selection.train_test_split(x_data, y_data, test_size=0.25, shuffle=True)\n",
    "\n",
    "# impute\n",
    "train_data_num = X_train.select_dtypes(exclude=['object'])\n",
    "test_data_num = X_test.select_dtypes(exclude=['object'])\n",
    "imputer = SimpleImputer()\n",
    "train_num_cleaned = imputer.fit_transform(train_data_num)\n",
    "test_num_cleaned = imputer.transform(test_data_num)\n",
    "\n",
    "# columns rename after imputing\n",
    "train_num_cleaned = pd.DataFrame(train_num_cleaned)\n",
    "test_num_cleaned = pd.DataFrame(test_num_cleaned)\n",
    "train_num_cleaned.columns = train_data_num.columns\n",
    "test_num_cleaned.columns = test_data_num.columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449b0474",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0d784234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34000, 1076)\n",
      "target\n",
      "0         17000\n",
      "1         17000\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nfrom sklearn.impute import SimpleImputer\\nfrom sklearn.preprocessing import MinMaxScaler\\n\\n# impute\\ntrain_data_num = X_train.select_dtypes(exclude=['object'])\\ntest_data_num = X_test.select_dtypes(exclude=['object'])\\nimputer = SimpleImputer()\\ntrain_num_cleaned = imputer.fit_transform(train_data_num)\\ntest_num_cleaned = imputer.transform(test_data_num)\\n\\n# columns rename after imputing\\ntrain_num_cleaned = pd.DataFrame(train_num_cleaned)\\ntest_num_cleaned = pd.DataFrame(test_num_cleaned)\\ntrain_num_cleaned.columns = train_data_num.columns\\ntest_num_cleaned.columns = test_data_num.columns\\n\\nscaler = MinMaxScaler()\\nscaler.fit(train_num_cleaned)\\ndata_train = scaler.transform(train_num_cleaned)\\ndata_test = scaler.transform(test_num_cleaned)\\n\""
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.model_selection\n",
    "\n",
    "data = pd.read_parquet('train_data.parquet', engine='pyarrow')\n",
    "useless_columns = ['id', 'sample_ml_new']\n",
    "\n",
    "\n",
    "y_data = data[\"target\"]\n",
    "x_data = data.drop([*useless_columns, 'target'], axis=1)\n",
    "\n",
    "sample_size = 17000 # Задайте желаемое количество строк для каждого класса\n",
    "frames = []\n",
    "classes = data['target'].unique()\n",
    "\n",
    "for i in classes:\n",
    "    if i == 0:  \n",
    "        g = data[data['target'] == i].sample(sample_size)\n",
    "    else:\n",
    "        g = data[data['target'] == i].sample(sample_size)\n",
    "    frames.append(g)\n",
    "\n",
    "equally_sampled = pd.concat(frames)\n",
    "equally_sampled = equally_sampled.drop(useless_columns, axis=1)\n",
    "y_equally_sampled = pd.DataFrame(equally_sampled['target'])\n",
    "x_equally_sampled = pd.DataFrame(equally_sampled.drop(['target'], axis=1))\n",
    "print(x_equally_sampled.shape)\n",
    "print(y_equally_sampled.value_counts())\n",
    "\n",
    "X_train, X_test, y_train,  y_test = sklearn.model_selection.train_test_split(x_equally_sampled, y_equally_sampled, test_size=0.25, shuffle=True)\n",
    "\n",
    "#X_train, X_test, y_train,  y_test = sklearn.model_selection.train_test_split(x_data, y_data, test_size=0.25, shuffle=True)\n",
    "\"\"\"\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# impute\n",
    "train_data_num = X_train.select_dtypes(exclude=['object'])\n",
    "test_data_num = X_test.select_dtypes(exclude=['object'])\n",
    "imputer = SimpleImputer()\n",
    "train_num_cleaned = imputer.fit_transform(train_data_num)\n",
    "test_num_cleaned = imputer.transform(test_data_num)\n",
    "\n",
    "# columns rename after imputing\n",
    "train_num_cleaned = pd.DataFrame(train_num_cleaned)\n",
    "test_num_cleaned = pd.DataFrame(test_num_cleaned)\n",
    "train_num_cleaned.columns = train_data_num.columns\n",
    "test_num_cleaned.columns = test_data_num.columns\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_num_cleaned)\n",
    "data_train = scaler.transform(train_num_cleaned)\n",
    "data_test = scaler.transform(test_num_cleaned)\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "761a246e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0         12791\n",
       "1         12709\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "233b0d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_19\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_19\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_135 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">551,424</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_116 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_136 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_117 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_137 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_118 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_138 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_119 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_139 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_135 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │         \u001b[38;5;34m551,424\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_116 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_136 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m131,328\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_117 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_137 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │          \u001b[38;5;34m65,792\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_118 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_138 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m16,448\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_119 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_139 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m65\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">765,057</span> (2.92 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m765,057\u001b[0m (2.92 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">765,057</span> (2.92 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m765,057\u001b[0m (2.92 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(512, input_shape=(1076, ), activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(256, activation = 'relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(256, activation = 'relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(64, activation = 'relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(1, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['AUC', 'Precision', 'Recall', 'F1Score'])\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "329cd18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - AUC: 0.4894 - F1Score: 0.6662 - Precision: 0.4956 - Recall: 0.7516 - loss: 0.6932 - val_AUC: 0.5000 - val_F1Score: 0.6709 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_loss: 0.6932\n",
      "Epoch 2/15\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - AUC: 0.5000 - F1Score: 0.6668 - Precision: 0.3737 - Recall: 0.1824 - loss: 0.6932 - val_AUC: 0.5000 - val_F1Score: 0.6709 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_loss: 0.6932\n",
      "Epoch 3/15\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - AUC: 0.4912 - F1Score: 0.6642 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - loss: 0.6932 - val_AUC: 0.5000 - val_F1Score: 0.6709 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_loss: 0.6932\n",
      "Epoch 4/15\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - AUC: 0.4976 - F1Score: 0.6619 - Precision: 0.3549 - Recall: 0.1131 - loss: 0.6932 - val_AUC: 0.5000 - val_F1Score: 0.6709 - val_Precision: 0.5048 - val_Recall: 1.0000 - val_loss: 0.6931\n",
      "Epoch 5/15\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - AUC: 0.5000 - F1Score: 0.6673 - Precision: 0.4935 - Recall: 0.4088 - loss: 0.6932 - val_AUC: 0.5000 - val_F1Score: 0.6709 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_loss: 0.6932\n",
      "Epoch 6/15\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - AUC: 0.4972 - F1Score: 0.6624 - Precision: 0.2035 - Recall: 0.0752 - loss: 0.6931 - val_AUC: 0.5000 - val_F1Score: 0.6709 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_loss: 0.6932\n",
      "Epoch 7/15\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - AUC: 0.4953 - F1Score: 0.6611 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - loss: 0.6931 - val_AUC: 0.5000 - val_F1Score: 0.6709 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_loss: 0.6932\n",
      "Epoch 8/15\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - AUC: 0.4975 - F1Score: 0.6598 - Precision: 0.1120 - Recall: 0.0278 - loss: 0.6931 - val_AUC: 0.5000 - val_F1Score: 0.6709 - val_Precision: 0.5048 - val_Recall: 1.0000 - val_loss: 0.6931\n",
      "Epoch 9/15\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - AUC: 0.4961 - F1Score: 0.6700 - Precision: 0.5040 - Recall: 0.9312 - loss: 0.6932 - val_AUC: 0.5000 - val_F1Score: 0.6709 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_loss: 0.6933\n",
      "Epoch 10/15\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - AUC: 0.4951 - F1Score: 0.6654 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - loss: 0.6932 - val_AUC: 0.5000 - val_F1Score: 0.6709 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_loss: 0.6932\n",
      "Epoch 11/15\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - AUC: 0.4985 - F1Score: 0.6664 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - loss: 0.6932 - val_AUC: 0.5000 - val_F1Score: 0.6709 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_loss: 0.6932\n",
      "Epoch 12/15\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - AUC: 0.4958 - F1Score: 0.6609 - Precision: 0.0145 - Recall: 4.1762e-04 - loss: 0.6931 - val_AUC: 0.5000 - val_F1Score: 0.6709 - val_Precision: 0.5048 - val_Recall: 1.0000 - val_loss: 0.6931\n",
      "Epoch 13/15\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - AUC: 0.5000 - F1Score: 0.6647 - Precision: 0.4945 - Recall: 0.7109 - loss: 0.6932 - val_AUC: 0.5000 - val_F1Score: 0.6709 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_loss: 0.6932\n",
      "Epoch 14/15\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - AUC: 0.4930 - F1Score: 0.6664 - Precision: 0.3378 - Recall: 0.0150 - loss: 0.6932 - val_AUC: 0.5000 - val_F1Score: 0.6709 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_loss: 0.6932\n",
      "Epoch 15/15\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - AUC: 0.4984 - F1Score: 0.6696 - Precision: 0.3508 - Recall: 0.1521 - loss: 0.6932 - val_AUC: 0.5000 - val_F1Score: 0.6709 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_loss: 0.6932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x15be20c3c90>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, y=y_train, batch_size=64, epochs=15, verbose=1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7b1bea21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.5000 - F1Score: 0.6736 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - loss: 0.6933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)\n",
    "model.save(\"model_ver_govno.h5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648ca778",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f757fd8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315c8344",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equallySample(data):\n",
    "    y_data = data[\"target\"]\n",
    "    x_data = data.drop(useless_columns, axis=1)\n",
    "    sample_size = 17000 # Задайте желаемое количество строк для каждого класса\n",
    "    frames = []\n",
    "    classes = data['target'].unique()\n",
    "\n",
    "    for i in classes:\n",
    "        if i == 0:  \n",
    "            g = data[data['target'] == i].sample(sample_size)\n",
    "        else:\n",
    "            g = data[data['target'] == i].sample(sample_size)\n",
    "        frames.append(g)\n",
    "\n",
    "    equally_sampled = pd.concat(frames)\n",
    "    equally_sampled['target'].value_counts()\n",
    "\n",
    "    X_train_equally_sampled, X_test_equally_sampled, y_train_equally_sampled,  y_test_equally_sampled = sklearn.model_selection.train_test_split(x_data, y_data, test_size=0.25, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e91258",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727a084d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74008f21",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

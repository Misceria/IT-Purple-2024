{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9139cbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import sklearn\n",
    "import time\n",
    "\n",
    "data = pd.read_parquet('train_data.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debea463",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Полезные частые функции\n",
    "\n",
    "useless_columns = ['id', 'target', 'sample_ml_new', 'feature68', 'feature69', 'feature144', 'feature160',\n",
    "                   'feature292', 'feature406', 'feature407', 'feature496', 'feature511',\n",
    "                   'feature625', 'feature661', 'feature663', 'feature669', 'feature678',\n",
    "                   'feature683', 'feature686', 'feature710', 'feature756', 'feature761',\n",
    "                   'feature765', 'feature801', 'feature802', 'feature806', 'feature807',\n",
    "                   'feature808', 'feature809', 'feature816', 'feature818', 'feature819',\n",
    "                   'feature955', 'feature956', 'feature957', 'feature958', 'feature959',\n",
    "                   'feature960', 'feature961', 'feature962', 'feature963', 'feature964',\n",
    "                   'feature965', 'feature966', 'feature967', 'feature968', 'feature969',\n",
    "                   'feature970', 'feature971', 'feature972', 'feature973', 'feature974', \n",
    "                   'feature975', 'feature976', 'feature977', 'feature978', 'feature979',\n",
    "                   'feature980', 'feature981', 'feature982', 'feature983', 'feature984', \n",
    "                   'feature1005', 'feature1006', 'feature1007', 'feature1008', 'feature1009',\n",
    "                   'feature1010', 'feature1011', 'feature1012', 'feature1013', 'feature1014',\n",
    "                   'feature1015', 'feature1016', 'feature1017', 'feature1018', 'feature1019',\n",
    "                   'feature1020', 'feature1021', 'feature1022', 'feature1023', 'feature1024',\n",
    "                   'feature1025', 'feature1026', 'feature1027', 'feature1028', 'feature1029',\n",
    "                   'feature1030', 'feature1031', 'feature1032', 'feature1033', 'feature1034']\n",
    "\n",
    "\n",
    "def metrics(y_true, y_preds):\n",
    "    acc = sklearn.metrics.accuracy_score(y_true, y_preds)  \n",
    "    rec = sklearn.metrics.recall_score(y_true, y_preds, average=None)\n",
    "    f1 = sklearn.metrics.f1_score(y_true, y_preds)\n",
    "    prec = \tsklearn.metrics.precision_score(y_true, y_preds)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_true, y_preds)\n",
    "    print('test-accuracy:', acc, ' \\ntest-recall:', rec, '\\ntest-f1_score:', f1, '\\ntest-precision_score:', prec, '\\ntest-roc_auc_score:', auc)\n",
    "    \n",
    "\n",
    "\n",
    "def equallySample(data):\n",
    "    y_data = data[\"target\"]\n",
    "    x_data = data.drop(useless_columns, axis=1)\n",
    "    sample_size = 17000 # Задайте желаемое количество строк для каждого класса\n",
    "    frames = []\n",
    "    classes = data['target'].unique()\n",
    "\n",
    "    for i in classes:\n",
    "        if i == 0:  \n",
    "            g = data[data['target'] == i].sample(sample_size)\n",
    "        else:\n",
    "            g = data[data['target'] == i].sample(sample_size)\n",
    "        frames.append(g)\n",
    "\n",
    "    equally_sampled = pd.concat(frames)\n",
    "    equally_sampled['target'].value_counts()\n",
    "\n",
    "    X_train_equally_sampled, X_test_equally_sampled, y_train_equally_sampled,  y_test_equally_sampled = sklearn.model_selection.train_test_split(x_data, y_data, test_size=0.25, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc61709",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics([0, 1, 1, 0, 1, 1, 1], [1, 0, 1, 0, 0, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c582df4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "useless_columns = ['id', 'target', 'sample_ml_new', 'feature68', 'feature69', 'feature144', 'feature160',\n",
    "                   'feature292', 'feature406', 'feature407', 'feature496', 'feature511',\n",
    "                   'feature625', 'feature661', 'feature663', 'feature669', 'feature678',\n",
    "                   'feature683', 'feature686', 'feature710', 'feature756', 'feature761',\n",
    "                   'feature765', 'feature801', 'feature802', 'feature806', 'feature807',\n",
    "                   'feature808', 'feature809', 'feature816', 'feature818', 'feature819',\n",
    "                   'feature955', 'feature956', 'feature957', 'feature958', 'feature959',\n",
    "                   'feature960', 'feature961', 'feature962', 'feature963', 'feature964',\n",
    "                   'feature965', 'feature966', 'feature967', 'feature968', 'feature969',\n",
    "                   'feature970', 'feature971', 'feature972', 'feature973', 'feature974', \n",
    "                   'feature975', 'feature976', 'feature977', 'feature978', 'feature979',\n",
    "                   'feature980', 'feature981', 'feature982', 'feature983', 'feature984', \n",
    "                   'feature1005', 'feature1006', 'feature1007', 'feature1008', 'feature1009',\n",
    "                   'feature1010', 'feature1011', 'feature1012', 'feature1013', 'feature1014',\n",
    "                   'feature1015', 'feature1016', 'feature1017', 'feature1018', 'feature1019',\n",
    "                   'feature1020', 'feature1021', 'feature1022', 'feature1023', 'feature1024',\n",
    "                   'feature1025', 'feature1026', 'feature1027', 'feature1028', 'feature1029',\n",
    "                   'feature1030', 'feature1031', 'feature1032', 'feature1033', 'feature1034']\n",
    "\n",
    "\n",
    "y_data = data[\"target\"]\n",
    "x_data = data.drop(useless_columns, axis=1)\n",
    "x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7813b92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train,  y_test = sklearn.model_selection.train_test_split(x_data, y_data, test_size=0.25, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a0c8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EQual size of targets\n",
    "\n",
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())\n",
    "\n",
    "\n",
    "sample_size = 17000 # Задайте желаемое количество строк для каждого класса\n",
    "frames = []\n",
    "classes = data['target'].unique()\n",
    "\n",
    "for i in classes:\n",
    "    if i == 0:  \n",
    "        g = data[data['target'] == i].sample(sample_size)\n",
    "    else:\n",
    "        g = data[data['target'] == i].sample(sample_size)\n",
    "    frames.append(g)\n",
    "\n",
    "equally_sampled = pd.concat(frames)\n",
    "equally_sampled['target'].value_counts()\n",
    "\n",
    "X_train_equally_sampled, X_test_equally_sampled, y_train_equally_sampled,  y_test_equally_sampled = sklearn.model_selection.train_test_split(x_data, y_data, test_size=0.25, shuffle=True)\n",
    "\"\"\"X_train_xgb_equally_sampled = xgb.DMatrix(X_train_equally_sampled, label=y_train_equally_sampled)\n",
    "X_test_xgb_equally_sampled = xgb.DMatrix(X_test_equally_sampled, label=y_test_equally_sampled)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bba7465",
   "metadata": {},
   "outputs": [],
   "source": [
    "equally_sampled['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d9eda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_data = xgb.DMatrix(x_data, label=y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87997bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'max_depth': 4,\n",
    "          'eta': 1,\n",
    "          'objective': \"binary:logistic\",\n",
    "          'nthread': -1,\n",
    "          'eval_metric': ['auc', 'map']}\n",
    "eval_list = [(X_test_xgb, \"Everything\")]\n",
    "num_rounds = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ac0cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "evals_result = dict()\n",
    "\n",
    "def objective(n_estimators, max_depth, classes_weight_o, learning_rate, gamma):\n",
    "    n_estimators = int(n_estimators)\n",
    "    max_depth = int(max_depth)\n",
    "    classes_weight_o = int(classes_weight_o)\n",
    "    classes_weights = class_weight.compute_sample_weight(\n",
    "    class_weight={0:1, 1:classes_weight_o},\n",
    "    y=y_train\n",
    ")   \n",
    "\n",
    "    \n",
    "    xgb_model = xgb.XGBClassifier(  n_estimators=n_estimators,\n",
    "                                    max_depth=max_depth,\n",
    "                                    learning_rate=learning_rate,\n",
    "                                    booster=\"gbtree\",\n",
    "                                    n_jobs=-1,\n",
    "                                    eval_metric=['auc', 'pre'],\n",
    "                                    gamma=gamma)\n",
    "\n",
    "    xgb_model.fit(X_train, y_train, eval_set=eval_list, sample_weight=classes_weights)\n",
    "    preds = xgb_model.predict(X_test)\n",
    "    return sklearn.metrics.f1_score(y_test, preds)\n",
    "\n",
    "\"\"\"parameters = {\n",
    "    'max_depth': [4, 20],\n",
    "    'learning_rate': [0.2],\n",
    "    'n_estimators': [20, 40],\n",
    "}\n",
    "\n",
    "params = {'max_depth': 6,\n",
    "          'eta': 1,\n",
    "          'objective': \"binary:logistic\",\n",
    "          'nthread': -1,\n",
    "          'eval_metric': ['auc', 'pre'],\n",
    "          'class_weight': {0:0.1, 1:100}}\"\"\"\n",
    "eval_list = [(X_test, y_test)]\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "\"\"\"classes_weights = class_weight.compute_sample_weight(\n",
    "    class_weight={0:1, 1:22},\n",
    "    y=y_train\n",
    ")\"\"\"\n",
    "#clf = sklearn.model_selection.GridSearchCV(xgb_model, parameters, scoring='f1_micro', n_jobs=-1, verbose=10)\n",
    "\n",
    "search_space = {\n",
    "    'max_depth': (4, 20),\n",
    "    'n_estimators': (10, 70),\n",
    "    \"classes_weight_o\": (10, 40),\n",
    "    'learning_rate': (0.001, 0.2),\n",
    "    'gamma': (0.01, 5)\n",
    "}\n",
    "import bayes_opt\n",
    "optimizer = bayes_opt.BayesianOptimization(\n",
    "                                f=objective,\n",
    "                                pbounds=search_space,\n",
    "                                random_state=12,\n",
    "                                allow_duplicate_points=True\n",
    "                              ) \n",
    "\n",
    "opt = optimizer.maximize(init_points=2, n_iter=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902c4cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.max['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbeaddcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_weights = class_weight.compute_sample_weight(\n",
    "    class_weight={0:1, 1:31},\n",
    "    y=y_train\n",
    ")   \n",
    "\n",
    "xgb_model = xgb.XGBClassifier(  gamma=4.8,\n",
    "                                learning_rate=0.152,\n",
    "                                max_depth=8,\n",
    "                                n_estimators=18,\n",
    "                                booster=\"gbtree\",\n",
    "                                n_jobs=-1,\n",
    "                                eval_metric=['auc', 'pre'],\n",
    "                                early_stopping_rounds=10)\n",
    "\n",
    "xgb_model.fit(X_train, y_train, eval_set=eval_list, sample_weight=classes_weights)\n",
    "preds = xgb_model.predict(X_test)\n",
    "metrics(y_test, preds)\n",
    "\n",
    "\n",
    "\"\"\"{'classes_weight_o': 31.438781865708886,\n",
    " 'gamma': 4.806812881469824,\n",
    " 'learning_rate': 0.15290427033360873,\n",
    " 'max_depth': 8.582152510429442,\n",
    " 'n_estimators': 18.513852056962605}\n",
    "                                    test-accuracy: 0.7220024017736174  \n",
    "                                    test-recall: [0.72583707 0.61577552] \n",
    "                                    test-f1_score: 0.13371074915441264 \n",
    "                                    test-precision_score: 0.07499798175506579 \n",
    "                                    test-roc_auc_score: 0.6708062939632549\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24eb72f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_preds = xgb_model.predict(X_test)\n",
    "y_true = list(y_test)\n",
    "print(*y_preds)\n",
    "\n",
    "#ev = clf.eval(X_test)\n",
    "metrics(y_true, y_preds)\n",
    "#print(ev, ' eval-recall:')\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_preds, y_test))\n",
    "cm = confusion_matrix(y_preds, y_test)\n",
    "acc = cm.diagonal().sum()/cm.sum()\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4529c1",
   "metadata": {},
   "source": [
    "# GRIDSEARCH XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508557a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'max_depth': range(2,10,2),\n",
    "    'learning_rate': np.linspace(.1, .6, 6),\n",
    "    'min_child_weight': range(1,10,2),\n",
    "}\n",
    "\n",
    "grid = sklearn.model_selection.GridSearchCV(\n",
    "    estimator = xgb.XGBClassifier(n_jobs=-1,\n",
    "                              n_estimators=500,\n",
    "                              random_state=0),\n",
    "    param_grid = params,\n",
    "    scoring='f1',  # <------Use `scoring` instead of `eval_metric`\n",
    ")\n",
    "\n",
    "eval_set = [(X_train_equally_sampled, y_train_equally_sampled),\n",
    "            (X_test_equally_sampled, y_test_equally_sampled)]\n",
    "\n",
    "grid.fit(X_train_equally_sampled, y_train_equally_sampled,\n",
    "         eval_set=eval_set,\n",
    "         early_stopping_rounds=25,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ca7743",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4af0bf2",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['feature5'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea000a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['feature2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3266a773",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=140\n",
    "corr = data[['target', 'feature'+str(x), 'feature'+str(x+1), 'feature'+str(x+2), 'feature'+str(x+3), \n",
    "                'feature'+str(x+4), 'feature'+str(x+5), 'feature'+str(x+6), 'feature'+str(x+7), 'feature'+str(x+8),\n",
    "                'feature'+str(x+9)]].corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6ff513",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot = data.boxplot(\"feature5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a7fef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import xgboost as xgb\n",
    "\n",
    "useless_columns = ['id', 'target', 'sample_ml_new', 'feature68', 'feature69', 'feature144', 'feature160',\n",
    "                   'feature292', 'feature406', 'feature407', 'feature496', 'feature511',\n",
    "                   'feature625', 'feature661', 'feature663', 'feature669', 'feature678',\n",
    "                   'feature683', 'feature686', 'feature710', 'feature756', 'feature761',\n",
    "                   'feature765', 'feature801', 'feature802', 'feature806', 'feature807',\n",
    "                   'feature808', 'feature809', 'feature816', 'feature818', 'feature819',\n",
    "                   'feature955', 'feature956', 'feature957', 'feature958', 'feature959',\n",
    "                   'feature960', 'feature961', 'feature962', 'feature963', 'feature964',\n",
    "                   'feature965', 'feature966', 'feature967', 'feature968', 'feature969',\n",
    "                   'feature970', 'feature971', 'feature972', 'feature973', 'feature974', \n",
    "                   'feature975', 'feature976', 'feature977', 'feature978', 'feature979',\n",
    "                   'feature980', 'feature981', 'feature982', 'feature983', 'feature984', \n",
    "                   'feature1005', 'feature1006', 'feature1007', 'feature1008', 'feature1009',\n",
    "                   'feature1010', 'feature1011', 'feature1012', 'feature1013', 'feature1014',\n",
    "                   'feature1015', 'feature1016', 'feature1017', 'feature1018', 'feature1019',\n",
    "                   'feature1020', 'feature1021', 'feature1022', 'feature1023', 'feature1024',\n",
    "                   'feature1025', 'feature1026', 'feature1027', 'feature1028', 'feature1029',\n",
    "                   'feature1030', 'feature1031', 'feature1032', 'feature1033', 'feature1034']\n",
    "\n",
    "data = pd.read_parquet('train_data.parquet', engine='pyarrow')\n",
    "y_data = data[\"target\"]\n",
    "\n",
    "x_data = data.drop(useless_columns, axis=1)\n",
    "print(x_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e45782",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train,  y_test = sklearn.model_selection.train_test_split(x_data, y_data, test_size=0.25, shuffle=True)\n",
    "\n",
    "X_train_xgb = xgb.DMatrix(X_train, label=y_train)\n",
    "X_test_xgb = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf370b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# impute\n",
    "train_data_num = X_train.select_dtypes(exclude=['object'])\n",
    "test_data_num = X_test.select_dtypes(exclude=['object'])\n",
    "imputer = SimpleImputer()\n",
    "train_num_cleaned = imputer.fit_transform(train_data_num)\n",
    "test_num_cleaned = imputer.transform(test_data_num)\n",
    "\n",
    "# columns rename after imputing\n",
    "train_num_cleaned = pd.DataFrame(train_num_cleaned)\n",
    "test_num_cleaned = pd.DataFrame(test_num_cleaned)\n",
    "train_num_cleaned.columns = train_data_num.columns\n",
    "test_num_cleaned.columns = test_data_num.columns\n",
    "\n",
    "\n",
    "cols_with_missing = [col for col in train_num_cleaned.columns\n",
    "                                if test_num_cleaned[col].isnull().any()]\n",
    "print(cols_with_missing)\n",
    "for col in cols_with_missing:\n",
    "    print(col, test_num_cleaned[col].isnull().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79906be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Изменение веса классов\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_data), y=y_data)\n",
    "\n",
    "# Создание модели с взвешиванием классов\n",
    "model = RandomForestClassifier(n_estimators=30, class_weight={0: 0.5, 1: 500.0})\n",
    "model.fit(train_num_cleaned, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bb4fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(test_num_cleaned)\n",
    "preds = list(map(round, preds))\n",
    "y_true = list(y_test)\n",
    "print(preds.count(1))\n",
    "#ev = bst.eval(X_test_xgb)\n",
    "\n",
    "\n",
    "rec = sklearn.metrics.recall_score(y_true, preds)\n",
    "f1 = sklearn.metrics.f1_score(y_true, preds)\n",
    "prec = \tsklearn.metrics.precision_score(y_true, preds)\n",
    "auc = sklearn.metrics.roc_auc_score(y_true, preds)\n",
    "print(' test-recall:', rec, ' test-f1_score:', f1, ' test-precision_score:', prec, ' test-roc_auc_score:', auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cce962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Методы борьбы с дисбалансом данных\n",
    "import sklearn\n",
    "print(sklearn.__version__)\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "data = pd.read_parquet('train_data.parquet', engine='pyarrow')\n",
    "y_data = data[\"target\"]\n",
    "x_data = data.drop(useless_columns, axis=1)\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "X_train, X_test, y_train,  y_test = sklearn.model_selection.train_test_split(x_data, y_data, test_size=0.25, shuffle=True)\n",
    "\n",
    "# impute\n",
    "train_data_num = X_train.select_dtypes(exclude=['object'])\n",
    "test_data_num = X_test.select_dtypes(exclude=['object'])\n",
    "imputer = SimpleImputer()\n",
    "train_num_cleaned = imputer.fit_transform(train_data_num)\n",
    "test_num_cleaned = imputer.transform(test_data_num)\n",
    "\n",
    "# columns rename after imputing\n",
    "train_num_cleaned = pd.DataFrame(train_num_cleaned)\n",
    "test_num_cleaned = pd.DataFrame(test_num_cleaned)\n",
    "train_num_cleaned.columns = train_data_num.columns\n",
    "test_num_cleaned.columns = test_data_num.columns\n",
    "\n",
    "# Создание экземпляра SMOTE\n",
    "smote = SMOTE()\n",
    "\n",
    "# Применение SMOTE к данным\n",
    "X_resampled, y_resampled = smote.fit_resample(train_num_cleaned, y_train)\n",
    "\n",
    "X_resampled_xgb = xgb.DMatrix(X_resampled, y_resampled)\n",
    "X_test_xgb = xgb.DMatrix(test_num_cleaned, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7482cb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'max_depth': 8,\n",
    "          'eta': 1,\n",
    "          'objective': \"binary:logistic\",\n",
    "          'nthread': -1,\n",
    "          'eval_metric': ['auc', 'pre']}\n",
    "eval_list = [(X_test_xgb, \"Everything\")]\n",
    "num_rounds = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f23f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef3f4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "evals_result = dict()\n",
    "bst = xgb.train(params, X_resampled_xgb, num_rounds, eval_list, evals=X_test_xgb, evals_result=evals_result)\n",
    "y_preds = bst.predict(X_test_xgb)\n",
    "preds = list(map(round, preds))\n",
    "y_true = list(y_test)\n",
    "metrics(y_true, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad67914",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics(y_true, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2e80bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение каждой моделей члена на подмножестве данных\n",
    "\n",
    "data = pd.read_parquet('train_data.parquet', engine='pyarrow')\n",
    "y_data = data[\"target\"]\n",
    "x_data = data.drop(useless_columns, axis=1)\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "X_train, X_test, y_train,  y_test = sklearn.model_selection.train_test_split(x_data, y_data, test_size=0.25, shuffle=True)\n",
    "\n",
    "# impute\n",
    "train_data_num = X_train.select_dtypes(exclude=['object'])\n",
    "test_data_num = X_test.select_dtypes(exclude=['object'])\n",
    "imputer = SimpleImputer()\n",
    "train_num_cleaned = imputer.fit_transform(train_data_num)\n",
    "test_num_cleaned = imputer.transform(test_data_num)\n",
    "\n",
    "# columns rename after imputing\n",
    "train_num_cleaned = pd.DataFrame(train_num_cleaned)\n",
    "test_num_cleaned = pd.DataFrame(test_num_cleaned)\n",
    "train_num_cleaned.columns = train_data_num.columns\n",
    "test_num_cleaned.columns = test_data_num.columns\n",
    "\n",
    "X_train_xgb = xgb.DMatrix(train_num_cleaned, y_train)\n",
    "X_test_xgb = xgb.DMatrix(test_num_cleaned, y_train)\n",
    "\n",
    "eval_list = [(X_test_xgb, \"Everything\")]\n",
    "num_rounds = 40\n",
    "ensemble = [xgb.train({'max_depth': x,\n",
    "          'eta': 1,\n",
    "          'objective': \"binary:logistic\",\n",
    "          'nthread': -1,\n",
    "          'eval_metric': ['auc', 'pre']}, X_train_xgb, num_rounds, eval_list, evals=X_test_xgb, evals_result=evals_result) for x in range(2, 10)]\n",
    "ind = 1\n",
    "\n",
    "\"\"\"for model in ensemble:\n",
    "    sample_indices = np.random.choice(len(X_train), size=len(X_train), replace=True)\n",
    "    X_subset, y_subset = X_train[sample_indices], y_train[sample_indices]\n",
    "    model.fit(X_subset, y_subset)\n",
    "    print(f\"Модель {ind} обучена\")\n",
    "    ind +=1\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e4da61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mode\n",
    "predictions = np.array([model.predict(X_test_xgb) for model in ensemble])\n",
    "new_predictions=[]\n",
    "for x in range(len(predictions[0])):\n",
    "    new_predictions.append(np.array([predictions[y][x] for y in range(len(predictions))]))\n",
    "ensemble_predictions = [int(mode(x.round())) for x in new_predictions]\n",
    "# Используем np.argmax для нахождения индекса наиболее часто встречающегося значения\n",
    "\n",
    "metrics(y_test, ensemble_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb26519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Кросс-обучение\n",
    "\n",
    "data = pd.read_parquet('train_data.parquet', engine='pyarrow')\n",
    "y_data = data[\"target\"]\n",
    "x_data = data.drop(useless_columns, axis=1)\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "X_train, X_test, y_train,  y_test = sklearn.model_selection.train_test_split(x_data, y_data, test_size=0.25, shuffle=True)\n",
    "\n",
    "# impute\n",
    "train_data_num = X_train.select_dtypes(exclude=['object'])\n",
    "test_data_num = X_test.select_dtypes(exclude=['object'])\n",
    "imputer = SimpleImputer()\n",
    "train_num_cleaned = imputer.fit_transform(train_data_num)\n",
    "test_num_cleaned = imputer.transform(test_data_num)\n",
    "\n",
    "# columns rename after imputing\n",
    "train_num_cleaned = pd.DataFrame(train_num_cleaned)\n",
    "test_num_cleaned = pd.DataFrame(test_num_cleaned)\n",
    "train_num_cleaned.columns = train_data_num.columns\n",
    "test_num_cleaned.columns = test_data_num.columns\n",
    "\n",
    "X_train_xgb = xgb.DMatrix(train_num_cleaned, y_train)\n",
    "X_test_xgb = xgb.DMatrix(test_num_cleaned, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b8382d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet('train_data.parquet', engine='pyarrow')\n",
    "y_data = data[\"target\"]\n",
    "x_data = data.drop(useless_columns, axis=1)\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "X_train, X_test, y_train,  y_test = sklearn.model_selection.train_test_split(x_data, y_data, test_size=0.25, shuffle=True)\n",
    "\n",
    "# impute\n",
    "train_data_num = X_train.select_dtypes(exclude=['object'])\n",
    "test_data_num = X_test.select_dtypes(exclude=['object'])\n",
    "imputer = SimpleImputer()\n",
    "train_num_cleaned = imputer.fit_transform(train_data_num)\n",
    "test_num_cleaned = imputer.transform(test_data_num)\n",
    "\n",
    "# columns rename after imputing\n",
    "train_num_cleaned = pd.DataFrame(train_num_cleaned)\n",
    "test_num_cleaned = pd.DataFrame(test_num_cleaned)\n",
    "train_num_cleaned.columns = train_data_num.columns\n",
    "test_num_cleaned.columns = test_data_num.columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449b0474",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0d784234",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'target'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'target'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m equally_sampled \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(frames)\n\u001b[0;32m     27\u001b[0m equally_sampled \u001b[38;5;241m=\u001b[39m equally_sampled\u001b[38;5;241m.\u001b[39mdrop(useless_columns, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 28\u001b[0m y_equally_sampled \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(equally_sampled[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     29\u001b[0m x_equally_sampled \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(equally_sampled\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(x_equally_sampled\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'target'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.model_selection\n",
    "\n",
    "data = pd.read_parquet('train_data.parquet', engine='pyarrow')\n",
    "useless_columns = ['id', 'sample_ml_new']\n",
    "\n",
    "\n",
    "y_data = data[\"target\"]\n",
    "x_data = data.drop([useless_columns, 'target'], axis=1)\n",
    "\n",
    "sample_size = 17000 # Задайте желаемое количество строк для каждого класса\n",
    "frames = []\n",
    "classes = data['target'].unique()\n",
    "\n",
    "for i in classes:\n",
    "    if i == 0:  \n",
    "        g = data[data['target'] == i].sample(sample_size)\n",
    "    else:\n",
    "        g = data[data['target'] == i].sample(sample_size)\n",
    "    frames.append(g)\n",
    "\n",
    "equally_sampled = pd.concat(frames)\n",
    "equally_sampled = equally_sampled.drop(useless_columns, axis=1)\n",
    "y_equally_sampled = pd.DataFrame(equally_sampled['target'])\n",
    "x_equally_sampled = pd.DataFrame(equally_sampled.drop(['target'], axis=1))\n",
    "print(x_equally_sampled.shape)\n",
    "print(y_equally_sampled.value_counts())\n",
    "\n",
    "X_train, X_test, y_train,  y_test = sklearn.model_selection.train_test_split(x_equally_sampled, y_equally_sampled, test_size=0.25, shuffle=True)\n",
    "\n",
    "#X_train, X_test, y_train,  y_test = sklearn.model_selection.train_test_split(x_data, y_data, test_size=0.25, shuffle=True)\n",
    "\"\"\"\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# impute\n",
    "train_data_num = X_train.select_dtypes(exclude=['object'])\n",
    "test_data_num = X_test.select_dtypes(exclude=['object'])\n",
    "imputer = SimpleImputer()\n",
    "train_num_cleaned = imputer.fit_transform(train_data_num)\n",
    "test_num_cleaned = imputer.transform(test_data_num)\n",
    "\n",
    "# columns rename after imputing\n",
    "train_num_cleaned = pd.DataFrame(train_num_cleaned)\n",
    "test_num_cleaned = pd.DataFrame(test_num_cleaned)\n",
    "train_num_cleaned.columns = train_data_num.columns\n",
    "test_num_cleaned.columns = test_data_num.columns\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_num_cleaned)\n",
    "data_train = scaler.transform(train_num_cleaned)\n",
    "data_test = scaler.transform(test_num_cleaned)\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "761a246e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature1067</th>\n",
       "      <th>feature1068</th>\n",
       "      <th>feature1069</th>\n",
       "      <th>feature1070</th>\n",
       "      <th>feature1071</th>\n",
       "      <th>feature1072</th>\n",
       "      <th>feature1073</th>\n",
       "      <th>feature1074</th>\n",
       "      <th>feature1075</th>\n",
       "      <th>feature1076</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>391020</th>\n",
       "      <td>1646</td>\n",
       "      <td>1759</td>\n",
       "      <td>17</td>\n",
       "      <td>103523</td>\n",
       "      <td>191</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4189</td>\n",
       "      <td>65979</td>\n",
       "      <td>96596</td>\n",
       "      <td>902</td>\n",
       "      <td>0</td>\n",
       "      <td>2615</td>\n",
       "      <td>1063</td>\n",
       "      <td>4189</td>\n",
       "      <td>65979</td>\n",
       "      <td>96596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292179</th>\n",
       "      <td>1761</td>\n",
       "      <td>1759</td>\n",
       "      <td>79</td>\n",
       "      <td>104150</td>\n",
       "      <td>62</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100692</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553127</th>\n",
       "      <td>1761</td>\n",
       "      <td>1759</td>\n",
       "      <td>46</td>\n",
       "      <td>105991</td>\n",
       "      <td>191</td>\n",
       "      <td>47</td>\n",
       "      <td>125</td>\n",
       "      <td>290</td>\n",
       "      <td>298</td>\n",
       "      <td>176</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389985</th>\n",
       "      <td>1761</td>\n",
       "      <td>1759</td>\n",
       "      <td>119</td>\n",
       "      <td>104664</td>\n",
       "      <td>134</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556738</th>\n",
       "      <td>1322</td>\n",
       "      <td>13</td>\n",
       "      <td>123</td>\n",
       "      <td>104715</td>\n",
       "      <td>104</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>47966</td>\n",
       "      <td>82895</td>\n",
       "      <td>106180</td>\n",
       "      <td>0</td>\n",
       "      <td>2659</td>\n",
       "      <td>38359</td>\n",
       "      <td>3107</td>\n",
       "      <td>47966</td>\n",
       "      <td>82895</td>\n",
       "      <td>106180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513099</th>\n",
       "      <td>1761</td>\n",
       "      <td>1759</td>\n",
       "      <td>44</td>\n",
       "      <td>97245</td>\n",
       "      <td>191</td>\n",
       "      <td>29</td>\n",
       "      <td>125</td>\n",
       "      <td>290</td>\n",
       "      <td>298</td>\n",
       "      <td>176</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291600</th>\n",
       "      <td>1761</td>\n",
       "      <td>1759</td>\n",
       "      <td>124</td>\n",
       "      <td>104253</td>\n",
       "      <td>11</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198232</th>\n",
       "      <td>1761</td>\n",
       "      <td>1759</td>\n",
       "      <td>126</td>\n",
       "      <td>104664</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>24489</td>\n",
       "      <td>39260</td>\n",
       "      <td>45617</td>\n",
       "      <td>23451</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24272</td>\n",
       "      <td>24489</td>\n",
       "      <td>39260</td>\n",
       "      <td>45617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317293</th>\n",
       "      <td>1761</td>\n",
       "      <td>1759</td>\n",
       "      <td>107</td>\n",
       "      <td>105729</td>\n",
       "      <td>191</td>\n",
       "      <td>166</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176880</th>\n",
       "      <td>1592</td>\n",
       "      <td>1759</td>\n",
       "      <td>135</td>\n",
       "      <td>105152</td>\n",
       "      <td>191</td>\n",
       "      <td>149</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>389711 rows × 1076 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
       "391020      1646      1759        17    103523       191        14         0   \n",
       "292179      1761      1759        79    104150        62         8         0   \n",
       "553127      1761      1759        46    105991       191        47       125   \n",
       "389985      1761      1759       119    104664       134        68         0   \n",
       "556738      1322        13       123    104715       104        32         0   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "513099      1761      1759        44     97245       191        29       125   \n",
       "291600      1761      1759       124    104253        11        54         0   \n",
       "198232      1761      1759       126    104664        15        14         0   \n",
       "317293      1761      1759       107    105729       191       166        50   \n",
       "176880      1592      1759       135    105152       191       149         0   \n",
       "\n",
       "        feature8  feature9  feature10  ...  feature1067  feature1068  \\\n",
       "391020        54        27          0  ...         4189        65979   \n",
       "292179         0         7          0  ...            0            0   \n",
       "553127       290       298        176  ...            0            0   \n",
       "389985         0        66          0  ...            0            0   \n",
       "556738        40        81          0  ...        47966        82895   \n",
       "...          ...       ...        ...  ...          ...          ...   \n",
       "513099       290       298        176  ...            0            0   \n",
       "291600         0       133          0  ...            0            0   \n",
       "198232         0        29          0  ...        24489        39260   \n",
       "317293         0         0         70  ...            0            0   \n",
       "176880       114         0          0  ...            0            0   \n",
       "\n",
       "        feature1069  feature1070  feature1071  feature1072  feature1073  \\\n",
       "391020        96596          902            0         2615         1063   \n",
       "292179       100692            0            0            0            0   \n",
       "553127            0            0            0            0            0   \n",
       "389985            0            0            0            0            0   \n",
       "556738       106180            0         2659        38359         3107   \n",
       "...             ...          ...          ...          ...          ...   \n",
       "513099            0            0            0            0            0   \n",
       "291600            0            0            0            0            0   \n",
       "198232        45617        23451            0            0        24272   \n",
       "317293            0            0            0            0            0   \n",
       "176880            0            0            0            0            0   \n",
       "\n",
       "        feature1074  feature1075  feature1076  \n",
       "391020         4189        65979        96596  \n",
       "292179            0            0       100692  \n",
       "553127            0            0            0  \n",
       "389985            0            0            0  \n",
       "556738        47966        82895       106180  \n",
       "...             ...          ...          ...  \n",
       "513099            0            0            0  \n",
       "291600            0            0            0  \n",
       "198232        24489        39260        45617  \n",
       "317293            0            0            0  \n",
       "176880            0            0            0  \n",
       "\n",
       "[389711 rows x 1076 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "233b0d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kseni\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_16\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_16\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_120 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">275,712</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_104 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_121 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_105 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_122 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_106 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_123 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_107 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_124 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_120 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m275,712\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_104 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_121 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │          \u001b[38;5;34m65,792\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_105 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_122 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m32,896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_106 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_123 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_107 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_124 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m65\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">382,721</span> (1.46 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m382,721\u001b[0m (1.46 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">382,721</span> (1.46 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m382,721\u001b[0m (1.46 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(256, input_shape=(1076, ), activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(256, activation = 'relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(128, activation = 'relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(64, activation = 'relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(1, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['AUC', 'Precision', 'Recall', 'F1Score'])\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "329cd18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m20243/24357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - AUC: 0.5006 - F1Score: 0.0698 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - loss: 0.2606"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(x\u001b[38;5;241m=\u001b[39mX_train, y\u001b[38;5;241m=\u001b[39my_train, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(X_test, y_test))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:118\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    116\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    120\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:323\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    322\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 323\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m    324\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(\n\u001b[0;32m    325\u001b[0m         step, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    326\u001b[0m     )\n\u001b[0;32m    327\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[0;32m    880\u001b[0m )\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1501\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1502\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1503\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1504\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1505\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1506\u001b[0m   )\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1515\u001b[0m   )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x=X_train, y=y_train, batch_size=16, epochs=15, verbose=1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7b1bea21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - AUC: 0.7120 - F1Score: 0.6543 - Precision: 0.6986 - Recall: 0.4906 - loss: 0.6272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.evaluate(data_test, y_test)\n",
    "model.save(\"model_ver_1.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f757fd8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315c8344",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equallySample(data):\n",
    "    y_data = data[\"target\"]\n",
    "    x_data = data.drop(useless_columns, axis=1)\n",
    "    sample_size = 17000 # Задайте желаемое количество строк для каждого класса\n",
    "    frames = []\n",
    "    classes = data['target'].unique()\n",
    "\n",
    "    for i in classes:\n",
    "        if i == 0:  \n",
    "            g = data[data['target'] == i].sample(sample_size)\n",
    "        else:\n",
    "            g = data[data['target'] == i].sample(sample_size)\n",
    "        frames.append(g)\n",
    "\n",
    "    equally_sampled = pd.concat(frames)\n",
    "    equally_sampled['target'].value_counts()\n",
    "\n",
    "    X_train_equally_sampled, X_test_equally_sampled, y_train_equally_sampled,  y_test_equally_sampled = sklearn.model_selection.train_test_split(x_data, y_data, test_size=0.25, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e91258",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727a084d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74008f21",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
